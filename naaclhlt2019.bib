Automatically generated by Mendeley Desktop 1.19.2
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@inproceedings{Shashi2018,
author = {Narayan, Shashi and Cohen, Shay B. and Lapata, Mirella},
booktitle = {Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing},
file = {:home/acp16hh/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - full-text(2).pdf:pdf},
title = {{Don't Give Me the Details, Just the Summary! Topic-aware Convolutional Neural Networks for Extreme Summarization.}},
year = {2018}
}
@article{Louis2013,
archivePrefix = {arXiv},
arxivId = {1604.07370},
author = {Louis, Annie and Nenkova, Ani},
doi = {10.1162/COLI},
eprint = {1604.07370},
file = {:home/acp16hh/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Louis, Nenkova - 2013 - Automatically Assessing Machine Summary Content Without a Gold Standard.pdf:pdf},
isbn = {9781608459858},
issn = {01272713},
journal = {Computational Linguistics},
number = {2},
pages = {267--300},
pmid = {22251136},
title = {{Automatically Assessing Machine Summary Content Without a Gold Standard}},
url = {http://www.seas.upenn.edu/},
volume = {39},
year = {2013}
}
@inproceedings{Hermann2015,
abstract = {Teaching machines to read natural language documents remains an elusive challenge. Machine reading systems can be tested on their ability to answer questions posed on the contents of documents that they have seen, but until now large scale training and test datasets have been missing for this type of evaluation. In this work we define a new methodology that resolves this bottleneck and provides large scale supervised reading comprehension data. This allows us to develop a class of attention based deep neural networks that learn to read real documents and answer complex questions with minimal prior knowledge of language structure.},
archivePrefix = {arXiv},
arxivId = {1506.03340},
author = {Hermann, Karl Moritz and Ko{\v{c}}isk{\'{y}}, Tom{\'{a}}{\v{s}} and Grefenstette, Edward and Espeholt, Lasse and Kay, Will and Suleyman, Mustafa and Blunsom, Phil},
booktitle = {Neural Information Processing Systems},
doi = {10.1109/72.410363},
eprint = {1506.03340},
file = {:home/acp16hh/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hermann et al. - 2015 - Teaching Machines to Read and Comprehend.pdf:pdf},
isbn = {1045-9227},
issn = {10495258},
pages = {1--14},
pmid = {18263409},
title = {{Teaching Machines to Read and Comprehend}},
url = {http://arxiv.org/abs/1506.03340},
year = {2015}
}
@article{Likert1932,
author = {Likert, Rensis},
journal = {Archives of psychology},
title = {{A technique for the measurement of attitudes.}},
year = {1932}
}
@inproceedings{Kryscinski2018,
abstract = {Abstractive text summarization aims to shorten long text documents into a human readable form that contains the most important facts from the original document. However, the level of actual abstraction as measured by novel phrases that do not appear in the source document remains low in existing approaches. We propose two techniques to improve the level of abstraction of generated summaries. First, we decompose the decoder into a contextual network that retrieves relevant parts of the source document, and a pretrained language model that incorporates prior knowledge about language generation. Second, we propose a novelty metric that is optimized directly through policy learning to encourage the generation of novel phrases. Our model achieves results comparable to state-of-the-art models, as determined by ROUGE scores and human evaluations, while achieving a significantly higher level of abstraction as measured by n-gram overlap with the source document.},
archivePrefix = {arXiv},
arxivId = {1808.07913},
author = {Kry{\'{s}}ci{\'{n}}ski, Wojciech and Paulus, Romain and Xiong, Caiming and Socher, Richard},
booktitle = {Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing},
eprint = {1808.07913},
file = {:home/acp16hh/Temp Mendeley/Improving Abstraction in Text Summarization.pdf:pdf},
pages = {1808--1817},
title = {{Improving Abstraction in Text Summarization}},
url = {http://arxiv.org/abs/1808.07913},
year = {2018}
}
@article{Federmann2012,
abstract = {We describe a focused effort to investigate the performance of phrase-based,human evaluation of machine translation output achieving a high annotatoragreement. We define phrase-based evaluation and describe the implementation ofAppraise, a toolkit that supports the manual evaluation of machine translationresults. Phrase ranking can be done using either a fine-grained six-way scoringscheme that allows to differentiate between "much better" and "slightlybetter", or a reduced subset of ranking choices. Afterwards we discuss kappavalues for both scoring models from several experiments conducted with humanannotators. Our results show that phrase-based evaluation can be used for fastevaluation obtaining significant agreement among annotators. The granularity ofranking choices should, however, not be too fine-grained as this seems toconfuse annotators and thus reduces the overall agreement. The work reported inthis paper confirms previous work in the field and illustrates that the usageof human evaluation in machine translation should be reconsidered. The Appraisetoolkit is available as open-source and can be downloaded from the author'swebsite.},
author = {Federmann, Christian},
doi = {10.2478/v10108-012-0006-9},
file = {:home/acp16hh/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Federmann - 2012 - Appraise an Open-Source Toolkit for Manual Evaluation of MT Output(2).pdf:pdf},
isbn = {2-9517408-6-7},
issn = {1804-0462},
journal = {The Prague Bulletin of Mathematical Linguistics},
keywords = {applications,evaluation,machine translation},
number = {-1},
pages = {130--134},
title = {{Appraise: an Open-Source Toolkit for Manual Evaluation of MT Output}},
url = {http://www.degruyter.com/view/j/pralin.2012.98.issue--1/v10108-012-0006-9/v10108-012-0006-9.xml},
volume = {98},
year = {2012}
}
@inproceedings{Celikyilmaz2018,
abstract = {Phosphoribosyl pyrophosphate (PPRibP) synthetase activity was studied in cultured fibroblasts and lymphoblasts from a male child (patient 2-A) in whom inherited purine nucleotide and uric acid overproduction are accompanied by neurological deficits. Chromatographed or partially purified preparations of the child's enzyme showed 5-6-fold increased inhibitory constants (I0.5) for the noncompetitive inhibitors GDP and 6-methylthioinosine monophosphate but normal responsiveness to the competitive inhibitors ADP and 2,3-diphosphoglycerate. Activation of the PPRibP synthetase of patient 2-A by Piwas also abnormal with 3-4-fold reduced apparent KDvalues for Pi. Superactivity of the PPRibP synthetase of this child thus appeared to result from a combination of regulatory defects; selective resistance to noncompetitive inhibitors and increased responsiveness to Piactivation. Selective growth of the patient's fibroblasts in medium containing 6-methylthioinosine confirmed the functional significance of the in vitro inhibitor resistance of the aberrant enzyme. Fibroblasts and lymphoblasts derived from patient 2-A showed increased concentrations and rates of generation of PPRibP as well as increased rates of the pathways of purine base salvage and purine nucleotide synthesis de novo. The magnitudes of these increases in the child's cells exceeded those in cells with catalytically superactive PPRibP synthetases. These alterations as well as the in vitro kinetic abnormalities in the patient 2-A enzyme were expressed to a reduced degree in fibroblasts from the child's affected mother, supporting the proposal that this woman is a heterozygous carrier for X-linked enzyme superactivity. {\textcopyright} 1986.},
archivePrefix = {arXiv},
arxivId = {1803.10357},
author = {Celikyilmaz, Asli and Bosselut, Antoine and He, Xiaodong and Choi, Yejin},
booktitle = {Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)},
doi = {10.1016/0304-4165(86)90151-0},
eprint = {1803.10357},
file = {:home/acp16hh/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Celikyilmaz et al. - Unknown - Deep Communicating Agents for Abstractive Summarization(2).pdf:pdf},
issn = {03044165},
title = {{Deep Communicating Agents for Abstractive Summarization}},
url = {https://arxiv.org/pdf/1803.10357.pdf http://arxiv.org/abs/1803.10357},
year = {2018}
}
@misc{Sandhaus2008,
address = {Philadelphia},
author = {Sandhaus, Evan},
publisher = {Linguistic Data Consortium},
title = {{The New York Times Annotated Corpus}},
year = {2008}
}
@inproceedings{Fan2018,
abstract = {Current models for document summarization disregard user preferences such as the desired length, style, the entities that the user might be interested in, or how much of the document the user has already read. We present a neural summarization model with a simple but effective mechanism to enable users to specify these high level attributes in order to control the shape of the final summaries to better suit their needs. With user input, our system can produce high quality summaries that follow user preferences. Without user input, we set the control variables automatically. On the full text CNN-Dailymail dataset, we outperform state of the art abstractive systems (both in terms of F1-ROUGE1 40.38 vs. 39.53 and human evaluation).},
archivePrefix = {arXiv},
arxivId = {1711.05217},
author = {Fan, Angela and Grangier, David and Auli, Michael},
booktitle = {ACL 2018 Workshop on Neural Machine Translation and Generation},
eprint = {1711.05217},
file = {:home/acp16hh/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fan, Grangier, Auli - Unknown - Controllable Abstractive Summarization.pdf:pdf},
title = {{Controllable Abstractive Summarization}},
url = {https://arxiv.org/pdf/1711.05217.pdf http://arxiv.org/abs/1711.05217},
year = {2018}
}
@article{Nenkova2004,
abstract = {We present an empirically grounded method for evaluating content selection in summariza- tion. It incorporates the idea that no single best model summary for a collection of documents exists. Our method quantifies the relative im- portance of facts to be conveyed. We argue that it is reliable, predictive and diagnostic, thus im- proves considerably over the shortcomings of the human evaluation method currently used in the Document Understanding Conference.},
author = {Nenkova, A and Passonneau, R},
file = {:home/acp16hh/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nenkova, Passonneau - Unknown - Evaluating Content Selection in Summarization The Pyramid Method.pdf:pdf},
journal = {Proceedings of HLT-NAACL},
keywords = {ani nenkova and rebecca,luating content selection in,passonneau,summarization,the pyramid method},
pages = {145--152},
title = {{Evaluating content selection in summarization: The pyramid method}},
url = {papers2://publication/uuid/DC675E84-0A45-48B7-A26C-F08B4B9398D3},
volume = {2004},
year = {2004}
}
@article{Nallapati2016a,
abstract = {In this work, we cast abstractive text summarization as a sequence-to-sequence problem and employ the framework of Attentional Encoder-Decoder Recurrent Neural Networks to this problem, outperforming state-of-the art model of Rush et. al. (2015) on two different corpora. We also move beyond the basic architecture, and propose several novel models to address important problems in summarization including modeling key-words, capturing the hierarchy of sentence-to-word structure and addressing the problem of words that are key to a document, but rare elsewhere. Our work shows that many of our proposed solutions contribute to further improvement in performance. In addition, we propose a new dataset consisting of multi-sentence summaries, and establish performance benchmarks for further research.},
archivePrefix = {arXiv},
arxivId = {1602.06023},
author = {Nallapati, Ramesh and Zhou, Bowen and dos Santos, Cicero Nogueira and Gulcehre, Caglar and Xiang, Bing},
eprint = {1602.06023},
file = {:home/acp16hh/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nallapati et al. - 2016 - Abstractive Text Summarization Using Sequence-to-Sequence RNNs and Beyond.pdf:pdf},
journal = {Proceedings of CoNLL},
pages = {280--290},
title = {{Abstractive Text Summarization Using Sequence-to-Sequence RNNs and Beyond}},
url = {http://arxiv.org/abs/1602.06023},
year = {2016}
}
@article{Woodworth1991,
author = {Woodworth, Jordan J Louviere and George G},
journal = {University of Alberta: Working Pa- per},
title = {{Best-worst scaling: A model for the largest difference judgments.}},
year = {1991}
}
@article{Clarke2010,
abstract = {Sentence compression holds promise for many applications ranging from summarization to subtitle generation. The task is typically performed on isolated sentences without taking the surrounding context into account, even though most applications would operate over entire documents. In this article we present a discourse-informed model which is capable of producing document compressions that are coherent and informative. Our model is inspired by theories of local coherence and formulated within the framework of integer linear programming. Experimental results show significant improvements over a state-of-the-art discourse agnostic approach.},
author = {Clarke, James and Lapata, Mirella},
doi = {10.1162/coli_a_00004},
file = {:home/acp16hh/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Clarke, Lapata - 2010 - Discourse Constraints for Document Compression.pdf:pdf},
isbn = {0891-2017},
issn = {08912017},
journal = {Computational Linguistics},
number = {3},
pages = {411--441},
pmid = {4120},
title = {{Discourse constraints for document compression}},
url = {https://www.mitpressjournals.org/doi/pdfplus/10.1162/coli{\_}a{\_}00004},
volume = {36},
year = {2010}
}
@article{Lin2004,
abstract = {ROUGE stands for Recall-Oriented Understudy for Gisting Evaluation. It includes measures to auto- matically determine the quality of a summary by comparing it to other (ideal) summaries created by humans. The measures count the number of over- lapping units such as n-gram, word sequences, and word pairs between the computer-generated sum- mary to be evaluated and the ideal summaries cre- ated by humans. This paper introduces four different ROUGE measures: ROUGE-N, ROUGE-L, ROUGE-W, and ROUGE-S included in the ROUGE summariza- tion evaluation package and their evaluatio ns. Three of them have been used in the Document Under- standing$\backslash$tConference$\backslash$t(DUC)$\backslash$t2004,$\backslash$ta$\backslash$tlarge -scale summarization evaluation sponsored by NIST.},
author = {Lin, Chin-Yew},
file = {:home/acp16hh/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lin - 2004 - Rouge A package for automatic evaluation of summaries.pdf:pdf},
issn = {00036951},
journal = {Proceedings of the workshop on Text Summarization Branches Out, Post-Conference Workshop of ACL 2004},
keywords = {2004,a package for automatic,barcelona,evaluation of summaries,post-conference workshop of acl,proceedings of workshop on,r ouge,spain,text summarization branches out},
number = {1},
pages = {25--26},
title = {{Rouge: A package for automatic evaluation of summaries}},
url = {papers2://publication/uuid/5DDA0BB8-E59F-44C1-88E6-2AD316DAEF85},
year = {2004}
}
@book{Louviere2015,
author = {Louviere, Jordan J and Flynn, Terry N and Fred, Anthony Alfred and Marley, John},
publisher = {Cambridge University Press},
title = {{Best-worst scaling: Theory, methods and applications}},
year = {2015}
}
@inproceedings{Paulus2018,
abstract = {Attentional, RNN-based encoder-decoder models for abstractive summarization have achieved good performance on short input and output sequences. However, for longer documents and summaries, these models often include repetitive and incoherent phrases. We introduce a neural network model with intra-attention and a new training method. This method combines standard supervised word prediction and reinforcement learning (RL). Models trained only with the former often exhibit "exposure bias" -- they assume ground truth is provided at each step during training. However, when standard word prediction is combined with the global sequence prediction training of RL the resulting summaries become more readable. We evaluate this model on the CNN/Daily Mail and New York Times datasets. Our model obtains a 41.16 ROUGE-1 score on the CNN/Daily Mail dataset, a 5.7 absolute points improvement over previous state-of-the-art models. It also performs well as the first abstractive model on the New York Times corpus. Human evaluation also shows that our model produces higher quality summaries.},
archivePrefix = {arXiv},
arxivId = {1705.04304},
author = {Paulus, Romain and Xiong, Caiming and Socher, Richard},
booktitle = {Proceedings of the 6th International Conference on Learning Representations},
eprint = {1705.04304},
file = {:home/acp16hh/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Paulus, Xiong, Socher - 2018 - A Deep Reinforced Model for Abstractive Summarization(2).pdf:pdf},
title = {{A Deep Reinforced Model for Abstractive Summarization}},
url = {http://arxiv.org/abs/1705.04304},
year = {2018}
}
@inproceedings{See2017,
abstract = {Neural sequence-to-sequence models have provided a viable new approach for abstractive text summarization (meaning they are not restricted to simply selecting and rearranging passages from the original text). However, these models have two shortcomings: they are liable to reproduce factual details inaccurately, and they tend to repeat themselves. In this work we propose a novel architecture that augments the standard sequence-to-sequence attentional model in two orthogonal ways. First, we use a hybrid pointer-generator network that can copy words from the source text via pointing, which aids accurate reproduction of information, while retaining the ability to produce novel words through the generator. Second, we use coverage to keep track of what has been summarized, which discourages repetition. We apply our model to the CNN / Daily Mail summarization task, outperforming the current abstractive state-of-the-art by at least 2 ROUGE points.},
archivePrefix = {arXiv},
arxivId = {1704.04368},
author = {See, Abigail and Liu, Peter J. and Manning, Christopher D.},
booktitle = {Proceedings of the 55th Annual Meeting of the ACL},
doi = {10.18653/v1/P17-1099},
eprint = {1704.04368},
file = {:home/acp16hh/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/See, Liu, Manning - 2017 - Get To The Point Summarization with Pointer-Generator Networks(2).pdf:pdf},
isbn = {9781945626753},
title = {{Get To The Point: Summarization with Pointer-Generator Networks}},
url = {http://arxiv.org/abs/1704.04368},
year = {2017}
}
@inproceedings{Gehrmann2018,
abstract = {Neural network-based methods for abstractive summarization produce outputs that are more fluent than other techniques, but which can be poor at content selection. This work proposes a simple technique for addressing this issue: use a data-efficient content selector to over-determine phrases in a source document that should be part of the summary. We use this selector as a bottom-up attention step to constrain the model to likely phrases. We show that this approach improves the ability to compress text, while still generating fluent summaries. This two-step process is both simpler and higher performing than other end-to-end content selection models, leading to significant improvements on ROUGE for both the CNN-DM and NYT corpus. Furthermore, the content selector can be trained with as little as 1,000 sentences, making it easy to transfer a trained summarizer to a new domain.},
archivePrefix = {arXiv},
arxivId = {1808.10792},
author = {Gehrmann, Sebastian and Deng, Yuntian and Rush, Alexander M},
booktitle = {Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing},
doi = {http://dx.doi.org/10.1016/j.jval.2015.09.2622},
eprint = {1808.10792},
file = {:home/acp16hh/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gehrmann, Deng, Rush - Unknown - Bottom-Up Abstractive Summarization.pdf:pdf},
issn = {1098-3015},
pmid = {26533926},
title = {{Bottom-Up Abstractive Summarization}},
url = {https://arxiv.org/pdf/1808.10792.pdf http://arxiv.org/abs/1808.10792},
year = {2018}
}
@article{Thurstone1994,
author = {Thurstone, L. L.},
file = {:home/acp16hh/Temp Mendeley/thurstone94law.pdf:pdf},
journal = {Psychological review},
number = {2},
pages = {255--270},
title = {{A Law of Comparative Judgment}},
volume = {101},
year = {1994}
}
